
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="April&#39;s Blog">
    <title>Dive into Deep Learning | 2. Preliminaries | 2.1 Data Manipulation - April&#39;s Blog</title>
    <meta name="author" content="April Lee">
    
        <meta name="keywords" content="hexo,javascript,data science,machine learning,">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"April Lee","sameAs":[],"image":"profile.jpg"},"articleBody":"Preliminaries\n딥러닝 학습에 필요한 것\n데이터를 저장하고 조작하는 기술\n다양한 소스에서 데이터를 수집하고 전처리하는 라이브러리\n고차원 데이터 요소에 적용되는 선형 대수 연산에 대한 기본 지식\nloss를 줄이기 위해 각 parameter 어느 방향으로 조정할지 결정할 수 있을 정도의 미적분학 지식\n미적분 지식을 잊어버려도 좋을 정도로 미분을 자동으로 계산할 수 있는 능력\n불확실성 하에서 추론하기 위한 확률에 대한 기본적인 유창성\n막힐 때 공식 문서에서 답을 찾을 수 있는 능력\n\n\n\nData Manipulation\nn-dimensional array &#x3D; tensor\n딥러닝 프레임워크의 tensor class\n자동 미분화 지원\nNumPy는 CPU에서만 실행되는 반면, tensor class는 GPU를 활용하여 수치 계산을 가속화\n\n\n\n\nGetting Started\n\n1 axis &#x3D; vector, 2 axes &#x3D; matrix, k &gt; 2 axes &#x3D; $k^{th}$-order tensor\n새로운 tensor는 메인 메모리에 저장되고 CPU 기반 계산을 위해 지정됨\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import torchx = torch.arange(12, dtype=torch.float32)x&#x27;&#x27;&#x27;tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])&#x27;&#x27;&#x27;x.numel()&#x27;&#x27;&#x27;12&#x27;&#x27;&#x27;x.shape&#x27;&#x27;&#x27;torch.Size([12])&#x27;&#x27;&#x27;X = x.reshape(3, 4)X&#x27;&#x27;&#x27;tensor([[ 0.,  1.,  2.,  3.],        [ 4.,  5.,  6.,  7.],        [ 8.,  9., 10., 11.]])&#x27;&#x27;&#x27;torch.zeros((2, 3, 4))&#x27;&#x27;&#x27;tensor([[[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]],        [[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]]])&#x27;&#x27;&#x27;torch.ones((2, 3, 4))&#x27;&#x27;&#x27;tensor([[[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]],        [[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]]])&#x27;&#x27;&#x27;torch.randn(3, 4)&#x27;&#x27;&#x27;tensor([[ 0.1351, -0.9099, -0.2028,  2.1937],       [-0.3200, -0.7545,  0.8086, -1.8730],       [ 0.3929,  0.4931,  0.9114, -0.7072]])&#x27;&#x27;&#x27;torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])&#x27;&#x27;&#x27;tensor([[2, 1, 4, 3],        [1, 2, 3, 4],        [4, 3, 2, 1]])&#x27;&#x27;&#x27;\n\nIndexing and Slicing\n123456789101112131415X[-1], X[1:3]&#x27;&#x27;&#x27;tensor([ 8.,  9., 10., 11.]),tensor([[ 4.,  5.,  6.,  7.],        [ 8.,  9., 10., 11.]]))&#x27;&#x27;&#x27;X[1, 2] = 17X&#x27;&#x27;&#x27;tensor([[ 0.,  1.,  2.,  3.],        [ 4.,  5., 17.,  7.],        [ 8.,  9., 10., 11.]]&#x27;&#x27;&#x27;\n\nOperation\n123456789101112131415161718192021222324252627282930313233343536373839404142434445torch.exp(x)&#x27;&#x27;&#x27;tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,         22026.4648,  59874.1406])&#x27;&#x27;&#x27;tx = torch.tensor([1.0, 2, 4, 8])y = torch.tensor([2, 2, 2, 2])x + y, x - y, x * y, x / y, x ** y&#x27;&#x27;&#x27;(tensor([ 3.,  4.,  6., 10.]), tensor([-1.,  0.,  2.,  6.]), tensor([ 2.,  4.,  8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1.,  4., 16., 64.]))&#x27;&#x27;&#x27; X = torch.arange(12, dtype=torch.float32).reshape((3,4))Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1&#x27;&#x27;&#x27;(tensor([[ 0.,  1.,  2.,  3.],         [ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.],         [ 2.,  1.,  4.,  3.],         [ 1.,  2.,  3.,  4.],         [ 4.,  3.,  2.,  1.]]), tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))&#x27;&#x27;&#x27;X == Y&#x27;&#x27;&#x27;tensor([[False,  True, False,  True],        [False, False, False, False],        [False, False, False, False]])&#x27;&#x27;&#x27;X.sum()&#x27;&#x27;&#x27;tensor(66.)&#x27;&#x27;&#x27;\n\nBroadcasting\n\n길이가 1인 축을 따라 요소를 복사하여 배열(하나 또는 둘 다) 확장 ⇒ 동일한 shape의 결과 배열에 대해 요소별 연산을 수행\n\n123456789101112131415161718a = torch.arange(3).reshape((3, 1))b = torch.arange(2).reshape((1, 2))a, b&#x27;&#x27;&#x27;(tensor([[0],         [1],         [2]]), tensor([[0, 1]]))&#x27;&#x27;&#x27;# a, b 모두 3 x 2 행렬로 확장a + b&#x27;&#x27;&#x27;tensor([[0, 1],        [1, 2],        [2, 3]])&#x27;&#x27;&#x27;\n\nSaving Memory\n\n머신러닝에서 메모리 누수가 발생하거나 실수로 이전 parameter를 참조하지 않도록 모든 참조를 업데이트하는 데 주의를 기울여야 함\n\n1234567891011121314151617181920212223242526# 메모리가 새로 할당됨before = id(Y)Y = Y + Xid(Y) == before&#x27;&#x27;&#x27;False&#x27;&#x27;&#x27;# slice notation을 사용해 연산 결과를 이전에 할당된 배열에 할당할 수 있음Z = torch.zeros_like(Y)print(&#x27;id(Z):&#x27;, id(Z))Z[:] = X + Yprint(&#x27;id(Z):&#x27;, id(Z))&#x27;&#x27;&#x27;id(Z): 140381179266448id(Z): 140381179266448&#x27;&#x27;&#x27;# X 값을 재사용하지 않는 경우, X[:] = X + Y 또는 X += Y를 사용해 연산의 메모리 오버헤드를 줄일 수 있음before = id(X)X += Yid(X) == before&#x27;&#x27;&#x27;True&#x27;&#x27;&#x27;\n\nConversion to Other Python Objects\n123456789101112131415# ndarray와 torch tensor는 기본 메모리를 공유함A = X.numpy()B = torch.from_numpy(A)type(A), type(B)&#x27;&#x27;&#x27;(numpy.ndarray, torch.Tensor)&#x27;&#x27;&#x27;# size 1인 tensor를 파이썬 스칼라로 변환a = torch.tensor([3.5])a, a.item(), float(a), int(a)&#x27;&#x27;&#x27;(tensor([3.5000]), 3.5, 3.5, 3)&#x27;&#x27;&#x27;\n\n","dateCreated":"2024-01-01T13:30:30+09:00","dateModified":"2024-01-01T13:38:46+09:00","datePublished":"2024-01-01T13:30:30+09:00","description":"Preliminaries\n딥러닝 학습에 필요한 것\n데이터를 저장하고 조작하는 기술\n다양한 소스에서 데이터를 수집하고 전처리하는 라이브러리\n고차원 데이터 요소에 적용되는 선형 대수 연산에 대한 기본 지식\nloss를 줄이기 위해 각 parameter 어느 방향으로 조정할지 결정할 수 있을 정도의 미적분학 지식\n미적분 지식을 잊어버려도 좋을 정도로 미분을 자동으로 계산할 수 있는 능력\n불확실성 하에서 추론하기 위한 확률에 대한 기본적인 유창성\n막힐 때 공식 문서에서 답을 찾을 수 있는 능력","headline":"Dive into Deep Learning | 2. Preliminaries | 2.1 Data Manipulation","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://8pril.github.io/2024/01/01/d2l_002/"},"publisher":{"@type":"Organization","name":"April Lee","sameAs":[],"image":"profile.jpg","logo":{"@type":"ImageObject","url":"profile.jpg"}},"url":"https://8pril.github.io/2024/01/01/d2l_002/"}</script>
    <meta name="description" content="Preliminaries 딥러닝 학습에 필요한 것 데이터를 저장하고 조작하는 기술 다양한 소스에서 데이터를 수집하고 전처리하는 라이브러리 고차원 데이터 요소에 적용되는 선형 대수 연산에 대한 기본 지식 loss를 줄이기 위해 각 parameter 어느 방향으로 조정할지 결정할 수 있을 정도의 미적분학 지식 미적분 지식을 잊어버려도 좋을 정도로 미분을 자동으">
<meta property="og:type" content="blog">
<meta property="og:title" content="Dive into Deep Learning | 2. Preliminaries | 2.1 Data Manipulation">
<meta property="og:url" content="https://8pril.github.io/2024/01/01/d2l_002/index.html">
<meta property="og:site_name" content="April&#39;s Blog">
<meta property="og:description" content="Preliminaries 딥러닝 학습에 필요한 것 데이터를 저장하고 조작하는 기술 다양한 소스에서 데이터를 수집하고 전처리하는 라이브러리 고차원 데이터 요소에 적용되는 선형 대수 연산에 대한 기본 지식 loss를 줄이기 위해 각 parameter 어느 방향으로 조정할지 결정할 수 있을 정도의 미적분학 지식 미적분 지식을 잊어버려도 좋을 정도로 미분을 자동으">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-01-01T04:30:30.000Z">
<meta property="article:modified_time" content="2024-01-01T04:38:46.737Z">
<meta property="article:author" content="April Lee">
<meta property="article:tag" content="hexo">
<meta property="article:tag" content="javascript">
<meta property="article:tag" content="data science">
<meta property="article:tag" content="machine learning">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="https://8pril.github.io/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-oe6pmhtecgpk141zte7urk6fz0voqiu1kgmkbtaihw7dncbn03msxqe79obs.min.css">

    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            April&#39;s Blog
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">April Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>author.bio</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="Search"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Dive into Deep Learning | 2. Preliminaries | 2.1 Data Manipulation
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2024-01-01T13:30:30+09:00">
	
		    Jan 01, 2024
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Deep-Learning/">Deep Learning</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><ul>
<li>딥러닝 학습에 필요한 것<ol>
<li>데이터를 저장하고 조작하는 기술</li>
<li>다양한 소스에서 데이터를 수집하고 전처리하는 라이브러리</li>
<li>고차원 데이터 요소에 적용되는 선형 대수 연산에 대한 기본 지식</li>
<li>loss를 줄이기 위해 각 parameter 어느 방향으로 조정할지 결정할 수 있을 정도의 미적분학 지식</li>
<li>미적분 지식을 잊어버려도 좋을 정도로 미분을 자동으로 계산할 수 있는 능력</li>
<li>불확실성 하에서 추론하기 위한 확률에 대한 기본적인 유창성</li>
<li>막힐 때 공식 문서에서 답을 찾을 수 있는 능력<span id="more"></span></li>
</ol>
</li>
</ul>
<h2 id="Data-Manipulation"><a href="#Data-Manipulation" class="headerlink" title="Data Manipulation"></a>Data Manipulation</h2><ul>
<li>n-dimensional array &#x3D; tensor</li>
<li>딥러닝 프레임워크의 tensor class<ul>
<li>자동 미분화 지원</li>
<li>NumPy는 CPU에서만 실행되는 반면, tensor class는 GPU를 활용하여 수치 계산을 가속화</li>
</ul>
</li>
</ul>
<ol>
<li><p><strong>Getting Started</strong></p>
<ul>
<li>1 axis &#x3D; vector, 2 axes &#x3D; matrix, k &gt; 2 axes &#x3D; $k^{th}$-order tensor</li>
<li>새로운 tensor는 메인 메모리에 저장되고 CPU 기반 계산을 위해 지정됨</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">12</span>, dtype=torch.float32)</span><br><span class="line">x</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">x.numel()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">12</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">x.shape</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([12])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">X = x.reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">X</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0.,  1.,  2.,  3.],</span></span><br><span class="line"><span class="string">        [ 4.,  5.,  6.,  7.],</span></span><br><span class="line"><span class="string">        [ 8.,  9., 10., 11.]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">torch.zeros((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0., 0., 0., 0.],</span></span><br><span class="line"><span class="string">         [0., 0., 0., 0.],</span></span><br><span class="line"><span class="string">         [0., 0., 0., 0.]],</span></span><br><span class="line"><span class="string">        [[0., 0., 0., 0.],</span></span><br><span class="line"><span class="string">         [0., 0., 0., 0.],</span></span><br><span class="line"><span class="string">         [0., 0., 0., 0.]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">torch.ones((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">         [1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">         [1., 1., 1., 1.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">         [1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">         [1., 1., 1., 1.]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0.1351, -0.9099, -0.2028,  2.1937],</span></span><br><span class="line"><span class="string">       [-0.3200, -0.7545,  0.8086, -1.8730],</span></span><br><span class="line"><span class="string">       [ 0.3929,  0.4931,  0.9114, -0.7072]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">torch.tensor([[<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[2, 1, 4, 3],</span></span><br><span class="line"><span class="string">        [1, 2, 3, 4],</span></span><br><span class="line"><span class="string">        [4, 3, 2, 1]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Indexing and Slicing</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">X[-<span class="number">1</span>], X[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([ 8.,  9., 10., 11.]),</span></span><br><span class="line"><span class="string">tensor([[ 4.,  5.,  6.,  7.],</span></span><br><span class="line"><span class="string">        [ 8.,  9., 10., 11.]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">X[<span class="number">1</span>, <span class="number">2</span>] = <span class="number">17</span></span><br><span class="line">X</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0.,  1.,  2.,  3.],</span></span><br><span class="line"><span class="string">        [ 4.,  5., 17.,  7.],</span></span><br><span class="line"><span class="string">        [ 8.,  9., 10., 11.]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Operation</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,</span></span><br><span class="line"><span class="string">        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,</span></span><br><span class="line"><span class="string">         22026.4648,  59874.1406])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">tx = torch.tensor([<span class="number">1.0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>])</span><br><span class="line">y = torch.tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">x + y, x - y, x * y, x / y, x ** y</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([ 3.,  4.,  6., 10.]),</span></span><br><span class="line"><span class="string"> tensor([-1.,  0.,  2.,  6.]),</span></span><br><span class="line"><span class="string"> tensor([ 2.,  4.,  8., 16.]),</span></span><br><span class="line"><span class="string"> tensor([0.5000, 1.0000, 2.0000, 4.0000]),</span></span><br><span class="line"><span class="string"> tensor([ 1.,  4., 16., 64.]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br><span class="line">X = torch.arange(<span class="number">12</span>, dtype=torch.float32).reshape((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">Y = torch.tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line">torch.cat((X, Y), dim=<span class="number">0</span>), torch.cat((X, Y), dim=<span class="number">1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[ 0.,  1.,  2.,  3.],</span></span><br><span class="line"><span class="string">         [ 4.,  5.,  6.,  7.],</span></span><br><span class="line"><span class="string">         [ 8.,  9., 10., 11.],</span></span><br><span class="line"><span class="string">         [ 2.,  1.,  4.,  3.],</span></span><br><span class="line"><span class="string">         [ 1.,  2.,  3.,  4.],</span></span><br><span class="line"><span class="string">         [ 4.,  3.,  2.,  1.]]),</span></span><br><span class="line"><span class="string"> tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],</span></span><br><span class="line"><span class="string">         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],</span></span><br><span class="line"><span class="string">         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">X == Y</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[False,  True, False,  True],</span></span><br><span class="line"><span class="string">        [False, False, False, False],</span></span><br><span class="line"><span class="string">        [False, False, False, False]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">X.<span class="built_in">sum</span>()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor(66.)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Broadcasting</strong></p>
<ul>
<li>길이가 1인 축을 따라 요소를 복사하여 배열(하나 또는 둘 다) 확장 ⇒ 동일한 shape의 결과 배열에 대해 요소별 연산을 수행</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">3</span>).reshape((<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">b = torch.arange(<span class="number">2</span>).reshape((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">a, b</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[0],</span></span><br><span class="line"><span class="string">         [1],</span></span><br><span class="line"><span class="string">         [2]]),</span></span><br><span class="line"><span class="string"> tensor([[0, 1]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># a, b 모두 3 x 2 행렬로 확장</span></span><br><span class="line">a + b</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0, 1],</span></span><br><span class="line"><span class="string">        [1, 2],</span></span><br><span class="line"><span class="string">        [2, 3]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Saving Memory</strong></p>
<ul>
<li>머신러닝에서 메모리 누수가 발생하거나 실수로 이전 parameter를 참조하지 않도록 모든 참조를 업데이트하는 데 주의를 기울여야 함</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 메모리가 새로 할당됨</span></span><br><span class="line">before = <span class="built_in">id</span>(Y)</span><br><span class="line">Y = Y + X</span><br><span class="line"><span class="built_in">id</span>(Y) == before</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># slice notation을 사용해 연산 결과를 이전에 할당된 배열에 할당할 수 있음</span></span><br><span class="line">Z = torch.zeros_like(Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;id(Z):&#x27;</span>, <span class="built_in">id</span>(Z))</span><br><span class="line">Z[:] = X + Y</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;id(Z):&#x27;</span>, <span class="built_in">id</span>(Z))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">id(Z): 140381179266448</span></span><br><span class="line"><span class="string">id(Z): 140381179266448</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># X 값을 재사용하지 않는 경우, X[:] = X + Y 또는 X += Y를 사용해 연산의 메모리 오버헤드를 줄일 수 있음</span></span><br><span class="line">before = <span class="built_in">id</span>(X)</span><br><span class="line">X += Y</span><br><span class="line"><span class="built_in">id</span>(X) == before</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Conversion to Other Python Objects</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ndarray와 torch tensor는 기본 메모리를 공유함</span></span><br><span class="line">A = X.numpy()</span><br><span class="line">B = torch.from_numpy(A)</span><br><span class="line"><span class="built_in">type</span>(A), <span class="built_in">type</span>(B)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(numpy.ndarray, torch.Tensor)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># size 1인 tensor를 파이썬 스칼라로 변환</span></span><br><span class="line">a = torch.tensor([<span class="number">3.5</span>])</span><br><span class="line">a, a.item(), <span class="built_in">float</span>(a), <span class="built_in">int</span>(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([3.5000]), 3.5, 3.5, 3)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="table-of-contents">Table of Contents</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Preliminaries"><span class="toc-text">Preliminaries</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-Manipulation"><span class="toc-text">Data Manipulation</span></a></li></ol></li></ol>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2024/07/20/ds_001/"
                    data-tooltip="데이터의 정합성과 무결성"
                    aria-label="PREVIOUS: 데이터의 정합성과 무결성"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2023/12/31/d2l_001/"
                    data-tooltip="Dive into Deep Learning | 1. Introduction"
                    aria-label="NEXT: Dive into Deep Learning | 1. Introduction"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://8pril.github.io/2024/01/01/d2l_002/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://8pril.github.io/2024/01/01/d2l_002/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://8pril.github.io/2024/01/01/d2l_002/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="Table of Contents">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2024 April Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2024/07/20/ds_001/"
                    data-tooltip="데이터의 정합성과 무결성"
                    aria-label="PREVIOUS: 데이터의 정합성과 무결성"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2023/12/31/d2l_001/"
                    data-tooltip="Dive into Deep Learning | 1. Introduction"
                    aria-label="NEXT: Dive into Deep Learning | 1. Introduction"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://8pril.github.io/2024/01/01/d2l_002/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://8pril.github.io/2024/01/01/d2l_002/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://8pril.github.io/2024/01/01/d2l_002/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="Table of Contents">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="5">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://8pril.github.io/2024/01/01/d2l_002/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://8pril.github.io/2024/01/01/d2l_002/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=https://8pril.github.io/2024/01/01/d2l_002/"
                        aria-label="Share on Google+"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Share on Google+</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">April Lee</h4>
        
            <div id="about-card-bio"></div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Undefined</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Seoul, Korea
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-11248vohh34kdb5akzskgpm91r7hq2frqwvepneuqpn484prc3ill6rrn6gx.min.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
